{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "absQmnk0TyPw"
      },
      "source": [
        "## Домашнее задание №3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH0vNvqbTyP7"
      },
      "source": [
        "### Укажите ФИО и группу"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM0E49_ATyP8"
      },
      "source": [
        "Добрый день,  \n",
        "\n",
        "Вам предлагается ответить на ряд вопросов для того, чтобы закрепить пройденный материал да и просто хорошо и с некоторой пользой провести несколько часов...  \n",
        "  \n",
        "Код, который вы пришлете, должен быть рабочим..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU6h9hb40hIG"
      },
      "source": [
        "### Импортируем необходимые модули "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPtDaHqP0hIG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Classroom/Методы машинного обучения/DA_ML_20')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSikQIJtTyP9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy, warnings, copy\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # библиотека для построения графиков\n",
        "import matplotlib.ticker as mticker\n",
        "import seaborn as sns # библиотека для построения графиков\n",
        "\n",
        "from sklearn import preprocessing, decomposition, manifold, model_selection, pipeline, cluster, datasets, mixture, metrics\n",
        "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, roc_curve, precision_score, roc_auc_score, f1_score\n",
        "\n",
        "from sklearn import linear_model as lm\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "from sklearn.datasets import make_regression, make_classification\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV, KFold\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "%matplotlib inline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRFC70wVTyP-"
      },
      "outputs": [],
      "source": [
        "## функция для генерации \"предсказаний\" с заданным уровнем ошибок \n",
        "def make_errors(Y, frac = .3, seed = 42):\n",
        "    \"\"\"\n",
        "    Y - our \"true\" binary labels\n",
        "    frac - the \"desired\" error rate\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    ## выберем индексы ответов, которые у нас будут ошибочными\n",
        "    ix = np.random.choice(range(len(Y)), replace=False, size =int(len(Y) * frac)) \n",
        "    Ys = copy.copy(Y) ## создадим копию массива с ответами, чтобы не изменять оригинальные ответы\n",
        "    Ys[ix] = np.abs(Y[ix] - 1) ## инвертируем метки классов\n",
        "    return Ys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Af5es_x0hII"
      },
      "source": [
        "### В этом задании у вас три сгенерированных заранее датасета, остальные есть в этом ноутбуке. В этом домашнем задании 5 пунктов + 1 бонусный. Всего за эту домашку можно получить 10 баллов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzBfc-oETyQA"
      },
      "source": [
        "Рекомендую внимательно ознакомиться с материалами, которые я вам выдал, посмотреть ссылки на дополнительные материалы, а для заинтересованных в теме &mdash; пройти дополнительные курсы по анализу данных и машинному обучению. Прошу обратить внимание на задания и вопросы, которые изредка, но встречаются в ноутбуках данного курса. Лучше их все-таки выполнить. Если не можете что-то сделать самостоятельно &mdash; спрашивайте."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcoeskU1TyQB"
      },
      "source": [
        "### 1. Оценка классификаторов (2 балла).\n",
        "\n",
        "1. В первой части задания вам необходимо работать с заранее сгенерированными массивами предсказанных и настоящих меток классов (Y_predicted, Y_true). Необходимо:\n",
        "\n",
        "    * Построить для них матрицу ошибок (confusion matrix)\n",
        "    * Определить Accuracy, Precision, Recall, F1-метрику\n",
        "    * Построить график ROC, определите значение AUC\n",
        "    * Проверить, можно ли улучшить качество предсказания метки класса? Верно ли подобрано пороговое значение? (бонусный пункт)\n",
        "    \n",
        "    \n",
        "2. Во второй части задания вам будет дан набор, в котором есть 200 объектов: 20 из класса 1 и 180 из класса 0. Для него будут доступны новые истинные метки классов, а также результаты предсказания нескольких алгоритмов. От вас требуется:\n",
        "\n",
        "    * Определить accuracy для каждого из методов. Какой из них лучше? Определить это также и для F1-метрики.\n",
        "    * Посчитать метрики accuracy и F1 для консенсусных предсказаний (пояснения в коде). Изменилось ли что-нибудь?\n",
        "    * Какой вывод вы можете сделать из данного упражнения?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hsr-FTl0hII"
      },
      "source": [
        "#### Первая часть"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uoTw1NJTyQC"
      },
      "outputs": [],
      "source": [
        "## результаты \"предсказания\"\n",
        "# np.random.seed(0) ## зафиксируем random seed\n",
        "# Yp = np.random.uniform(0, 0.9, 100) ## синтезируем ответы\n",
        "Y_predicted = np.array([0.49393215, 0.64367043, 0.54248704, 0.49039486, 0.38128932, 0.5813047 , 0.39382849, 0.8025957 ,\n",
        "            0.86729648, 0.34509737, 0.71255253, 0.47600543, 0.5112401 , 0.83303697, 0.06393245, 0.07841637,\n",
        "            0.01819656, 0.74935786, 0.70034108, 0.78301093, 0.88075651, 0.71924271, 0.41533143, 0.70247626, \n",
        "            0.10644698, 0.57592892, 0.12901796, 0.85020203, 0.46966349, 0.37319575, 0.23810005, 0.69681032, \n",
        "            0.4105353 , 0.51159055, 0.01691082, 0.55587195, 0.55088615, 0.5552406 , 0.84937327, 0.61363827,\n",
        "            0.32355711, 0.39332876, 0.62786808, 0.05420292, 0.60009004, 0.60357408, 0.1893443 , 0.11603367,\n",
        "            0.28388552, 0.32733969, 0.51317709, 0.39474136, 0.88953645, 0.09184033, 0.18798908, 0.14517857,\n",
        "            0.58779749, 0.22796244, 0.4196797 , 0.21998303, 0.14307263, 0.09933763, 0.59069663, 0.12436466,\n",
        "            0.17692413, 0.33185265, 0.73889391, 0.08739115, 0.75415042, 0.08648857, 0.87881352, 0.42178608,\n",
        "            0.87908498, 0.54436097, 0.66533722, 0.03526901, 0.25452627, 0.10817691, 0.26652618, 0.10685495,\n",
        "            0.28618486, 0.3728367 , 0.05773275, 0.62322491, 0.50994131, 0.23885054, 0.47092325, 0.08454646,\n",
        "            0.51835185, 0.83636658, 0.28671206, 0.60066934, 0.11861808, 0.64469448, 0.26046548, 0.16487223,\n",
        "            0.52786164, 0.01809679, 0.74604603, 0.00422593])\n",
        "\n",
        "## настоящие ответы - метки классов\n",
        "Y_true = np.array([1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
        "            0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
        "            1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
        "            1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
        "            0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0], dtype=np.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufOP1f8c0hIJ"
      },
      "outputs": [],
      "source": [
        "## 1. Постройте матрицу ошибок -- confusion matrix\n",
        "## Тут должен быть ваш код"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLuDFrZl0hIJ"
      },
      "outputs": [],
      "source": [
        "## 2. Определите Accuracy, Precision, Recall, F1-метрику\n",
        "#accuracy_score\n",
        "#precision_score\n",
        "#recall_score\n",
        "#f1_score\n",
        "## Тут должен быть ваш код"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6amhSicj0hIJ"
      },
      "outputs": [],
      "source": [
        "## 3. Постройте график ROC, определите значение AUC\n",
        "## для примера смотрите ноутбук №3\n",
        "## Тут должен быть ваш код"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlNs2WaR0hIJ"
      },
      "outputs": [],
      "source": [
        "## * 4. Проверьте, можно ли улучшить качество предсказания метки класса? Верно ли подобрано пороговое значение?\n",
        "## Тут должен быть ваш код"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik1bA_zSTyQE"
      },
      "source": [
        "#### Вторая часть "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AijKl-LHTyQE"
      },
      "outputs": [],
      "source": [
        "## Вам дан набор, в котором есть 200 объектов: 20 из класса 1 и 180 из класса 0\n",
        "## Y   - истинные метки классов\n",
        "## Yp1 - результаты предсказания алгоритма 1\n",
        "## Yp2 - результаты предсказания алгоритма 2\n",
        "## Yp3 - результаты предсказания алгоритма 3\n",
        "## Yp4 - результаты предсказания алгоритма 4\n",
        "np.random.seed(42)\n",
        "Y =  np.hstack( [ np.ones(20), np.zeros(180) ] ) \n",
        "np.random.shuffle(Y)\n",
        "Yp1 = make_errors(Y, 0.25, seed = 9)\n",
        "Yp2 = make_errors(Y, 0.25, seed = 42)\n",
        "Yp3 = make_errors(Y, 0.25, seed = 1024)\n",
        "Yp4 = np.zeros(200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgUJVgWv0hIK"
      },
      "outputs": [],
      "source": [
        "## Определите accuracy каждого из методов\n",
        "## <ваш код>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-82aG4d0hIK"
      },
      "outputs": [],
      "source": [
        "## Какой из методов лучше?\n",
        "## <ваш комментарий>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w17Vbn70hIK"
      },
      "outputs": [],
      "source": [
        "## Повторите все для метрики F1\n",
        "\n",
        "## <ваш код>\n",
        "## <ваш комментарий>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZwZjmEETyQF"
      },
      "outputs": [],
      "source": [
        "## Используйте результаты моделей №1-3 -- возьмем и усредним результаты их предсказаний:\n",
        "Yc = ((Yp1 + Yp2 + Yp3)/3 > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSTcRCXQ0hIK"
      },
      "outputs": [],
      "source": [
        "## Оцените результат по метрикам Accuracy и F1, стал ли он лучше? Почему?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIWDwrkE0hIL"
      },
      "outputs": [],
      "source": [
        "## Можете добавить к вычислению консенсуса результат Yp4. Определите метрики Accuracy и F1. Что изменилось? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXh8Ua4Q0hIL"
      },
      "outputs": [],
      "source": [
        "## Какой вывод вы можете сделать из данного упражнения?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVuxart8TyQF"
      },
      "source": [
        "### 2. Исследование корреляций (1 балл).\n",
        "\n",
        "В вашем распоряжении оказался некий датасет (наблюдения за экспрессией некоторых генов, рекомендательная база данных для ассортимента интернет-маркета, относительный расход электричества в домах в некотором городе и т.д.). Вам необходимо:\n",
        "\n",
        "1. Посмотреть корреляцию датасета с целевой переменной. Есть ли такие признаки, абсолютное значение коэффициента корреляции для которых > 0.5?\n",
        "2. Посмотреть корреляцию между признаками внутри датасета. Какое распределение у абсолютных значений коэффициентов корреляции Пирсона для первого признака? Много ли там признаков, абсолютное значение коэффициента корреляции для которых > 0.5?\n",
        "3. Увеличить/уменьшить количество наблюдений N = 10, N = 100\n",
        "4. Уменьшить количество признаков в данных: D = 100, 500, 5000\n",
        "5. Дать ответы на вопросы:\n",
        "    - Чем обусловлены наши проблемы с этим набором данных? \n",
        "    - Как можно бороться со случайными корреляциями?\n",
        "    - Почему при тестировании нескольких статистических гипотез необходимо проводить поправку на множественную проверку гипотез?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE9Dm_CsTyQG"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "N = 30    ## количество наблюдений\n",
        "D = 10000 ## размерность наших данных -- например, число некоторых генов, экспрессию которых мы изучаем\n",
        "Y = pd.Series(np.random.normal(0, 1, N)) ## это какие-то наши целевые значения\n",
        "X = pd.DataFrame( np.random.normal(0, 1, (N, D)) ) ## это наши независимые переменные, скажем экспрессия некоторых генов\n",
        "## как мы видим все эти данные абсолютно случайные..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPv3XM9lTyQG"
      },
      "outputs": [],
      "source": [
        "## можем ли мы получить высокую корреляцию с нашей целевой переменной?\n",
        "ccY = X.corrwith(Y)\n",
        "## посмотрите на распределение значений. Есть ли такие \"гены\", абсолютное значение коэффициента корреляции для которых > 0.5\n",
        "## <ваш код>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Zkot5qfTyQH"
      },
      "outputs": [],
      "source": [
        "## теперь давайте проведем аналогичный эксперимент для нашей матрицы X... \n",
        "## определим \"коэкспрессию\" ...\n",
        "ccX = X.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gUA1UzlTyQH"
      },
      "outputs": [],
      "source": [
        "## Посмотрите на респределение абсолютных значений коэффициентов корреляции Пирсона\n",
        "## Например для первого гена из нашего массива данных:\n",
        "ccX.iloc[0,1:]\n",
        "## много ли получилось генов с коэфф. корреляции > 0.5?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1jjTuTuTyQH"
      },
      "outputs": [],
      "source": [
        "## Попробуйте увеличить/уменьшить количество наблюдений N = 10, N = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLV0FcZi0hIM"
      },
      "outputs": [],
      "source": [
        "## Попробуйте использовать меньшее количество переменных: D = 100, 500, 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxGsb6eX0hIM"
      },
      "outputs": [],
      "source": [
        "## Чем обусловлены наши проблемы с этим набором данных? Как можно бороться со случайными корреляциями?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGSGaq-zTyQI"
      },
      "outputs": [],
      "source": [
        "## Почему при тестировании нескольких статистических гипотез необходимо проводить поправку на множественную проверку гипотез?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIDosp0S0hIM"
      },
      "source": [
        "Тем, для кого выражение \"p-hacking\" незнакомо -- обязательно смотреть статьи: \n",
        "* https://en.wikipedia.org/wiki/Data_dredging\n",
        "* https://ru.wikipedia.org/wiki/Поправка_на_множественную_проверку_гипотез\n",
        "* http://www.machinelearning.ru/wiki/index.php?title=Множественная_проверка_гипотез"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKmL27S7TyQI"
      },
      "source": [
        "Для развлечения:  \n",
        "http://www.tylervigen.com/spurious-correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf-VloicTyQJ"
      },
      "source": [
        "### 3. Полиномиальная регрессия (1 балл).\n",
        "\n",
        "Вам предлагается самим поэксперементировать с построением полиномиальной регрессией, способной приблизить функцию **myy**. Постройте модели для нескольких степеней (1, 2, 4, 15) и определите среднеквадратичную ошибку предсказания. Какая модель является на ваш взгляд оптимальной? Почему? С какими проблемами мы столкнулись при построении моделей (что иллюстрирует этот эксперимент)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLdYRFNlTyQJ"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model as lm\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wx_O_XYTyQJ"
      },
      "outputs": [],
      "source": [
        "def myy(x):\n",
        "    return np.cos(1.5 * np.pi * x)\n",
        "\n",
        "def poly_lm(X,y, dg):\n",
        "    polynomial_features = PolynomialFeatures(degree=dg,\n",
        "                                             include_bias=False)\n",
        "    linear_regression = lm.LinearRegression()\n",
        "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
        "                         (\"linear_regression\", linear_regression)])\n",
        "    pipeline.fit(X[:, np.newaxis], y)\n",
        "    return pipeline\n",
        "\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(70) ## набор тренировочных данных X\n",
        "y = myy(X) + np.random.randn(70) * 0.1 ## набор истинных значений y для тренировочного набора\n",
        "\n",
        "X_test = np.linspace(-.01, 1.01, 30)  ## набор тестовых данных X\n",
        "y_test = myy(X_test) ## набор истинных значений y для тестового набора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OisaH3ivTyQK"
      },
      "outputs": [],
      "source": [
        "## получим модель для степени = 1, 2, 4, 15\n",
        "mod1 = poly_lm( X, y, dg = 1  )\n",
        "## выполним предсказание для тестового набора\n",
        "y_t1 = mod1.predict(X_test[:, np.newaxis])\n",
        "## определите среднеквадратичную ошибку предсказания для тестового набора и для тренировочного набора\n",
        "# metrics.mean_squared_error(y_true, y_predicted)\n",
        "## <ваш код>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1PcY88y0hIN"
      },
      "outputs": [],
      "source": [
        "## аналогично поступите для степени 2, 4 и 15\n",
        "## <ваш код>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAbz2VfC0hIN"
      },
      "outputs": [],
      "source": [
        "## Какая модель является на ваш взгляд оптимальной? Почему? С какими проблемами мы столкнулись при построении моделей?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmJebmrrTyQK"
      },
      "source": [
        "### 4. Шкалирование данных (2 балла).\n",
        "\n",
        "Для этого задания часть датасетов генерируется в коде, часть - приложена в виде файла к вашему ДЗ. Необходимо ответить на следующие вопросы:\n",
        "1. Зачем нужно проводить шкалирование данных? \n",
        "2. Всегда ли это нужно делать?\n",
        "3. Какой/какие из предоставленных вам наборов надо шкалировать? Обоснуйте свой ответ при помощи кода."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CHlsZmfTyQL"
      },
      "outputs": [],
      "source": [
        "X1, Y1 = make_classification(n_samples=500, n_features=50, \n",
        "                             n_informative=20, n_redundant=10, \n",
        "                             n_repeated=0, n_classes=3, \n",
        "                             n_clusters_per_class=1, \n",
        "                             weights=None, # The proportions of samples assigned to each class. \n",
        "                                           # If None, then classes are balanced.\n",
        "                             flip_y=0.01, class_sep=1.0, \n",
        "                             hypercube=True,\n",
        "                             shift=1.0, \n",
        "                             scale=None, \n",
        "                             shuffle = False,\n",
        "                             random_state=42)\n",
        "\n",
        "X2, Y2 = make_classification(n_samples=500, n_features=50, \n",
        "                             n_informative=20, n_redundant=10, \n",
        "                             n_repeated=0, n_classes=3, \n",
        "                             n_clusters_per_class=1, \n",
        "                             weights=None, # The proportions of samples assigned to each class. \n",
        "                                           # If None, then classes are balanced.\n",
        "                             flip_y=0.01, class_sep=1.0, \n",
        "                             hypercube=True,\n",
        "                             shift=1.0, \n",
        "                             scale=1, \n",
        "                             shuffle = False,\n",
        "                             random_state=42)\n",
        "\n",
        "XY3 = pd.read_csv('X3.csv')\n",
        "X3, Y3 = XY3.iloc[:,1:], XY3.Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atDQHuzcTyQL"
      },
      "outputs": [],
      "source": [
        "## <ваш код>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq3-xs0nTyQM"
      },
      "source": [
        "### 5. Неразмеченные данные (2 балла).\n",
        "\n",
        "Вам дан набор неразмеченных данных X4. Проведите его анализ с помощью PCA, визуализируйте результат. Какие выводы вы можете сделать? Чем может быть обусловлена такая картина? Как стоит поступить? Можете сразу проверить свою гипотезу."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooDM5TqCTyQM"
      },
      "outputs": [],
      "source": [
        "X4 = pd.read_csv('X4.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwabfzBiTyQN"
      },
      "outputs": [],
      "source": [
        "## Проведите его анализ с помощью PCA. \n",
        "## Визуализируйте результат.\n",
        "## <Ваш код>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw-EHdFW0hIO"
      },
      "outputs": [],
      "source": [
        "## Какие выводы вы можете сделать? Чем может быть обусловлена такая картина? Как стоит поступить?\n",
        "## Ваши комментарии"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79oS2ZZHTyQN"
      },
      "source": [
        "### 6. Серийные эффекты (2 балла)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0gywyn-TyQQ"
      },
      "source": [
        "Здесь мы наглядно познакомимся с тем, что такое серийные эффекты (batch effect). \n",
        "Вам дан набор данных 'expr_data.tsv'. \n",
        "1. Какая переменная в вашем наборе данных указывает на возможное присутствие серийных эффектов? С чем могут быть связаны серийные эффекты?\n",
        "2. Ваша задача попытаться найти маркерные признаки. Имеет ли ваша задача решение?\n",
        "3. Какие проблемы вы заметили в данных? Можно ли с ними бороться? Имеет ли это смысл в данном случае?\n",
        "\n",
        "Обязательно посмотрите на все переменные. Можете провести PCA, покрасить точки по классам, по каким-то интересным факторам..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tm2vZyipTyQR"
      },
      "outputs": [],
      "source": [
        "## <здесь должен быть ваш код>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}