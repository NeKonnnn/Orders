{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c8bde51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input as preprocess_input_vggface\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot.tf_keras import PlotLossesCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d430e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv('./_datasets/train.csv', index_col=0)\n",
    "df['image_path'] = df['image_path'].apply(lambda x: x.replace('train', '_datasets/train_dataset'))\n",
    "\n",
    "# Разделение данных на тренировочные и тестовые выборки\n",
    "train_df = df.sample(frac=0.8, random_state=200)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "def preprocess_input_facenet(image_):\n",
    "    \"\"\"\n",
    "    image_ -- тензор размера (1, H, W, 3)\n",
    "    return: картинка, с примененным preprocess_input(..., version=2) из keras_vggface\n",
    "    \"\"\"\n",
    "    preprocessed = preprocess_input_vggface(image_, version=2)\n",
    "    return preprocessed\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 224\n",
    "N_CLASSES = 9\n",
    "\n",
    "# Генератор для тренировочных данных с аугментацией\n",
    "train_generator = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    brightness_range=(0.5, 1.5),\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    preprocessing_function=preprocess_input_facenet\n",
    ")\n",
    "\n",
    "train_data_gen = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='emotion',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    shuffle=True,\n",
    "    interpolation='nearest'\n",
    ")\n",
    "\n",
    "# Генератор для тестовых данных без аугментации\n",
    "val_generator = ImageDataGenerator(preprocessing_function=preprocess_input_facenet)\n",
    "\n",
    "val_data_gen = val_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='image_path',\n",
    "    y_col='emotion',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False,\n",
    "    interpolation='nearest'\n",
    ")\n",
    "\n",
    "# Загрузка модели VGGFace с использованием ResNet50\n",
    "vggface_model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3))\n",
    "vggface_model.summary()\n",
    "\n",
    "# Добавление дополнительных слоев к модели\n",
    "model = Sequential([\n",
    "    vggface_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(N_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# Настройка компиляции модели\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=5e-4,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "# Определение коллбеков для сохранения модели и изменения скорости обучения\n",
    "checkpoint = ModelCheckpoint(\n",
    "    './_models/_checkpoints/classification/best_model.h5',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "EPOCHS = 50\n",
    "history = model.fit(\n",
    "    train_data_gen, \n",
    "    epochs=EPOCHS, \n",
    "    validation_data=val_data_gen, \n",
    "    callbacks=[checkpoint, PlotLossesCallback()]\n",
    ")\n",
    "\n",
    "# Оценка модели\n",
    "model.evaluate(val_data_gen)\n",
    "\n",
    "# Визуализация результатов\n",
    "def deprocess_image(vggface_image):\n",
    "    image = np.copy(vggface_image)\n",
    "    image[..., 0] += 91.4953\n",
    "    image[..., 1] += 103.8827\n",
    "    image[..., 2] += 131.0912\n",
    "    image = image[..., ::-1]\n",
    "    image = image.astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "def show_faces(images, real_emotion=None, predicted_emotion=None):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    emotion_mapping = dict(list(enumerate(('Anger', 'Contempt', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise', 'Uncertain'))))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(deprocess_image(images[i]))\n",
    "        real_str = f\"Real: {emotion_mapping[int(real_emotion[i])]}, \" if real_emotion is not None else \"Real: N/A, \"\n",
    "        pred_str = f\"Pred: {emotion_mapping[np.argmax(predicted_emotion[i])]}, \" if predicted_emotion is not None else \"Pred: N/A, \"\n",
    "        correct = (real_emotion is not None and np.argmax(predicted_emotion[i]) == int(real_emotion[i]))\n",
    "        title_obj = plt.title(f\"{real_str}\\n{pred_str}\")\n",
    "        plt.subplots_adjust(wspace=0.4)\n",
    "        if not correct:\n",
    "            plt.setp(title_obj, color='r')\n",
    "\n",
    "sample_validation_images, sample_validation_labels = next(val_data_gen)\n",
    "predicted = model.predict(sample_validation_images)\n",
    "show_faces(sample_validation_images, real_emotion=sample_validation_labels, predicted_emotion=predicted)\n",
    "\n",
    "# Сохранение модели и весов\n",
    "model_json = model.to_json()\n",
    "with open(\"./_models/emotion_classification/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('./_models/emotion_classification/saved_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
